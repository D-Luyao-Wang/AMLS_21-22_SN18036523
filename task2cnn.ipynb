{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np  \n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.')\n",
    "else:\n",
    "    print('CUDA is available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "#data\n",
    "from skimage import io, transform\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "training_path='/Users/luyaowang/Desktop/dataset/' \n",
    "test_path='/Users/luyaowang/Desktop/testcnn/' \n",
    "\n",
    "batch_size=4\n",
    "#Depends on memory size\n",
    "\n",
    "num_workers=0\n",
    "transform = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "    \n",
    "# import datasets using ImageFolder\n",
    "training_dataset = datasets.ImageFolder(training_path, transform)\n",
    "test1_dataset = datasets.ImageFolder(test_path, transform)\n",
    "\n",
    "\n",
    "\n",
    "#Classification train vali\n",
    "length=len(training_dataset)\n",
    "training_size,validatation_size=int(0.8*length),int(0.2*length)\n",
    "training_set,validatation_set=torch.utils.data.random_split(training_dataset,[training_size,validatation_size])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#split test part in the training data\n",
    "# validatation_size, testing_size=int(0.1*length),int(0.1*length)\n",
    "# validatation_set, testing_set=torch.utils.data.random_split(validatation_set,[validatation_size, testing_size])\n",
    "\n",
    "\n",
    "\n",
    "# put into DataLoaders\n",
    "training_loader = DataLoader(dataset=training_set, batch_size=batch_size, \n",
    "                          shuffle=True, num_workers=num_workers)\n",
    "validation_loader = DataLoader(dataset=validatation_set, batch_size=batch_size, \n",
    "                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "\n",
    "\n",
    "#test before\n",
    "# testing_loader = DataLoader(dataset=testing_set, batch_size=batch_size, \n",
    "#                           shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test1_loader = DataLoader(dataset=test1_dataset, batch_size=batch_size, \n",
    "                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classes = ['glioma_tumor','meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "\n",
    "class BrainTumorModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainTumorModel, self).__init__()\n",
    "        self.c0 = nn.Conv2d(1, 32, kernel_size=(3, 3)) #1 channel to 32\n",
    "        self.r = nn.ReLU()\n",
    "        self.m0 = nn.MaxPool2d(2, 2)#Pick largest\n",
    "        self.c1 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
    "        self.m1 = nn.MaxPool2d(2, 2)\n",
    "        self.c2 = nn.Conv2d(64, 128, kernel_size=(3, 3))\n",
    "        self.m2 = nn.MaxPool2d(2, 2)\n",
    "        self.c3 = nn.Conv2d(128, 128, kernel_size=(3, 3))#different weight get more feature\n",
    "        self.m3 = nn.MaxPool2d(2, 2)\n",
    "        self.f = nn.Flatten()\n",
    "        self.dr = nn.Dropout(0.2)#remove 20%\n",
    "        self.l0 = nn.Linear(25088, 512)\n",
    "        self.l1 = nn.Linear(512, 4)\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.c0(X)\n",
    "        X = self.r(X)\n",
    "        X = self.m0(X)\n",
    "        X = self.c1(X)\n",
    "        X = self.r(X)\n",
    "        X = self.m1(X)\n",
    "        X = self.c2(X)\n",
    "        X = self.r(X)\n",
    "        X = self.m2(X)\n",
    "        X = self.c3(X)\n",
    "        X = self.r(X)\n",
    "        X = self.m3(X)\n",
    "        X = self.f(X)\n",
    "        X = self.dr(X)\n",
    "        X = self.l0(X)\n",
    "        X = self.l1(X)\n",
    "\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BrainTumorModel(\n",
       "  (c0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (r): ReLU()\n",
       "  (m0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (m1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (m2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (m3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (f): Flatten(start_dim=1, end_dim=-1)\n",
       "  (dr): Dropout(p=0.2, inplace=False)\n",
       "  (l0): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (l1): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BrainTumorModel()\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=3e-4)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 1.012749 \tValidation Loss: 0.782550\n",
      "Validation loss decreasd from inf to 0.782550. Model is saving.\n",
      "Epoch: 1 \tTraining Loss: 0.748705 \tValidation Loss: 0.777993\n",
      "Validation loss decreasd from 0.782550 to 0.777993. Model is saving.\n"
     ]
    }
   ],
   "source": [
    "#traning\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "#list value for plot\n",
    "valid_loss_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    \n",
    "    #Clear after each epoch\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    " \n",
    "    model.train()\n",
    "    for data, target in training_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad() # clear optimizer\n",
    "        output = model(data)#predicted outputs\n",
    "        loss = criterion(output, target)# calculate batch loss\n",
    "        loss.backward()\n",
    "        optimizer.step()#optimization\n",
    "        train_loss += loss.item()*data.size(0)# update training loss\n",
    "        \n",
    "  \n",
    "\n",
    "    #validate\n",
    "    model.eval()\n",
    "    for data, target in validation_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()  \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0) # update validation loss \n",
    "    \n",
    "    train_loss = train_loss/len(training_loader.sampler)# calculate average losses\n",
    "    valid_loss = valid_loss/len(validation_loader.sampler)\n",
    "    \n",
    "    \n",
    "    # using for draw the figure\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreasd from {:.6f} to {:.6f}. Model is saving.'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'brain_test.pt')# save model if validation loss smaller then before\n",
    "        valid_loss_min = valid_loss\n",
    "    else:\n",
    "        print('Model does not need to be saved.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_lab = list(range(50))\n",
    "\n",
    "# x_lab = list(range(n_epochs))\n",
    "plt.title('Compare train loss and validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "l1,=plt.plot(x_lab, train_loss_list)\n",
    "l2,=plt.plot(x_lab, valid_loss_list)\n",
    "plt.legend(handles=[l1,l2],labels=['train loss','validation loss'])\n",
    "# plt.plot(x_lab, train_loss_list)\n",
    "# plt.plot(x_lab, valid_loss_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test loss\n",
    "# clear test loss\n",
    "test_loss = 0.0\n",
    "\n",
    "class_correct = [0 for _ in range(4)]\n",
    "class_total = [0 for _ in range(4)]\n",
    "\n",
    "model.eval()\n",
    "counter=0\n",
    "\n",
    "\n",
    "for data, target in test1_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "       \n",
    "\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    _, pred = torch.max(output, 1) # change to predict class\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))  # compare label\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "    \n",
    "#accuracy\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        label = target[i].data\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "        counter += 1\n",
    "       \n",
    "\n",
    "#average test loss\n",
    "test_loss = test_loss/len(test1_loader.dataset)\n",
    "print('Test loss is {:.3f}'.format(test_loss))\n",
    "\n",
    "for i in range(4):\n",
    "    print('Test accuracy for is %5s: %.3f%% (%2d/%2d)' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i],\n",
    "        np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "\n",
    "        \n",
    "print('Accuracy for the test data is  %.3f%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
